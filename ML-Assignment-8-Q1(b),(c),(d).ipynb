{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1(b) Creating the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, train_data,sizes,actions):\n",
    "        \n",
    "       \n",
    "        \n",
    "        self.num_layers = len(sizes)\n",
    "        \n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.actions = actions\n",
    "        self.activations = 0\n",
    "        self.z = 0\n",
    "        self.delta_b = 0\n",
    "        self.delta_w = 0\n",
    "        self.train_data = train_data\n",
    "\n",
    "    #Forward Pass\n",
    "    def forwardpass(self, x):\n",
    "        act = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        cnt = 0\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, act)+b\n",
    "            zs.append(z)\n",
    "            if(self.actions[cnt]=='sigmoid'):\n",
    "                act = self.sigmoid(z)\n",
    "            elif(self.actions[cnt]=='relu'):\n",
    "                act = self.relu(z)\n",
    "            else: \n",
    "                act = z\n",
    "            activations.append(act)\n",
    "            cnt+=1\n",
    "        self.activations = activations\n",
    "        self.z = zs\n",
    "        return activations[-1]\n",
    "        \n",
    "    \n",
    "    def SGD_train(self,alpha):\n",
    "        for x,y in self.train_data: \n",
    "            net.forwardpass(x)\n",
    "            net.backprop(y)\n",
    "            net.gradient_descent(alpha)\n",
    "\n",
    "    #Back Propogation\n",
    "    def backprop(self, y):\n",
    "        \n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        activations = self.activations\n",
    "        zs = self.z\n",
    "        if(self.actions[-1]=='sigmoid'): \n",
    "            delta = self.initial_derivative(activations[-1], y)*self.sigmoid_prime(zs[-1])\n",
    "        elif(self.actions[-1]=='relu'):\n",
    "            delta = self.initial_derivative(activations[-1],y)*self.relu_prime(zs[-1])\n",
    "        else: \n",
    "            delta = self.initial_derivative(activations[-1],y)*np.ones(np.shape(zs[-1]))\n",
    "            \n",
    "\n",
    "        delta_b[-1] = delta     \n",
    "        delta_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        \n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            if(self.actions[-l] == 'sigmoid'):\n",
    "                sp = self.sigmoid_prime(z)\n",
    "                \n",
    "            elif(self.actions[-l] == 'linear'):\n",
    "                \n",
    "                sp = np.ones(np.shape(z))\n",
    "                                                                       \n",
    "            else: \n",
    "                sp = self.relu_prime(z)\n",
    "                                                            \n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            delta_b[-l] = delta\n",
    "            delta_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        \n",
    "        self.delta_b = delta_b \n",
    "        self.delta_w = delta_w\n",
    "   \n",
    "    #Gradient Descent\n",
    "    def gradient_descent(self,alpha):\n",
    "        updated_weights = []\n",
    "        updated_biases = []\n",
    "        for w,b,db,dw in zip(self.weights,self.biases,self.delta_b,self.delta_w):\n",
    "            \n",
    "            w = w-alpha*dw\n",
    "            b = b-alpha*db\n",
    "            updated_weights.append(w)\n",
    "            updated_biases.append(b)\n",
    "        self.weights = updated_weights\n",
    "        self.biases = updated_biases\n",
    "    \n",
    "\n",
    "            \n",
    "    \n",
    "    def initial_derivative(self, output_activations, y):\n",
    "       \n",
    "        return (output_activations-y)\n",
    "\n",
    "    #Activation functions\n",
    "    def sigmoid(self,z):\n",
    "    \n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "    \n",
    "    def sigmoid_prime(self,z):\n",
    "   \n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "\n",
    "    def relu(self,z):\n",
    "        z[z<0] = 0\n",
    "        return z\n",
    "    \n",
    "    def relu_prime(self,z):\n",
    "        z[z>0] = 1\n",
    "        z[z<0] = 0\n",
    "        return z\n",
    "    \n",
    "    def evaluate(self,test_data):\n",
    "        \n",
    "        \n",
    "        test_results = [(np.argmax(net.forwardpass(x)),y) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)*1.0/len(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1(c) Testing on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "net =  Network(training_data,[784,30,10],['sigmoid','sigmoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.SGD_train(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation on MNIST dataset. \n",
    "\n",
    "test_results = [(np.argmax(net.forwardpass(x)),y)\n",
    "                    for (x, y) in test_data]\n",
    "validation_results = [(np.argmax(net.forwardpass(x)),y) for (x,y) in validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy 0.918\n",
      "test accuracy 0.9092\n"
     ]
    }
   ],
   "source": [
    "print \"validation accuracy\", sum(int(x==y) for (x,y) in validation_results)/10000.\n",
    "print \"test accuracy\", sum(int(x == y) for (x, y) in test_results)/10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1(d) Training Network on real estate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('real_estate.xlsx')\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[1:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_train.values.reshape(-1,1,1)\n",
    "X_t = X_train.values.reshape(-1,6,1)\n",
    "\n",
    "y_te = y_test.values.reshape(-1,1,1)\n",
    "X_te = X_test.values.reshape(-1,6,1)\n",
    "\n",
    "y_v = y_val.values.reshape(-1,1,1)\n",
    "X_v = X_val.values.reshape(-1,6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = zip(X_t,y_t)\n",
    "test_data = zip(X_te,y_te)\n",
    "val_data = zip(X_v,y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "net =  Network(train_data,[6,1],['sigmoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.SGD_train(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_results = [net.forwardpass(x)[0][0]\n",
    "                    for (x, y) in test_data]\n",
    "validation_results = [net.forwardpass(x)[0][0] for (x,y) in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Test RMSE and MSE are', 0.015391994387526446, 'and', 0.0002369134912256456)\n",
      "('The Val RMSE and MSE are', 0.05472659861223529, 'and', 0.002995000595664714)\n"
     ]
    }
   ],
   "source": [
    "TMSE = sum(y_test-test_results)**2/len(y_test)\n",
    "TRMSE = np.sqrt(TMSE)\n",
    "\n",
    "VMSE = sum(validation_results-y_val)**2/len(y_val)\n",
    "RVMSE = np.sqrt(VMSE)\n",
    "\n",
    "print(\"The Test RMSE and MSE are\",TRMSE ,\"and\", TMSE)\n",
    "print(\"The Val RMSE and MSE are\",RVMSE,\"and\",VMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
