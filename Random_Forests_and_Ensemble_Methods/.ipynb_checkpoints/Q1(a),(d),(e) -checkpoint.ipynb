{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from collections import Counter\n",
    "import time\n",
    "import random\n",
    "from random import sample \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit learn classifier with train values\n",
    "def scikit_learn(train):\n",
    "    y = train[train.columns[-1]].values.tolist()\n",
    "    x = train[train.columns[:-1]].values.tolist()\n",
    "    clf = sklearn.tree.DecisionTreeClassifier()\n",
    "    clf.fit(x,y)\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of scikit-learn on a given row. \n",
    "def scikit_predict(clf,test):\n",
    "    x_test = test[test.columns[:-1]].values.tolist()\n",
    "    y_test = test[test.columns[-1]].values.tolist()\n",
    "    cnt = 0\n",
    "    accurate = 0\n",
    "    for index,row in enumerate(x_test):\n",
    "        cnt+=1\n",
    "        test = clf.predict([row])\n",
    "        if(test[0]==y_test[index]): \n",
    "            accurate+=1\n",
    "    return 1.0*accurate/cnt\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of each row in the dataset. \n",
    "def class_counts(dataset):\n",
    "    \n",
    "    last_name = dataset.columns[-1]  \n",
    "    last_col = dataset[last_name]\n",
    "    counter = Counter(last_col) \n",
    "    return counter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def most_frequent(counter): \n",
    "    maxi = 0\n",
    "    ele = 0\n",
    "    for i in counter.keys():\n",
    "        if(counter[i]>maxi):\n",
    "            ele = i\n",
    "            maxi = counter[i]\n",
    "    return ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "\n",
    "    \n",
    "    classes = class_counts(rows)\n",
    "    \n",
    "    total=len(rows)\n",
    "    p=0\n",
    "    for i in classes:\n",
    "        p+= (classes[i]*1.0 / total)**2\n",
    "        \n",
    "        \n",
    "        \n",
    "    return 1-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(upper, lower, current):\n",
    "    upper_len = len(upper)\n",
    "    lower_len = len(lower)\n",
    "    p = lower_len*1.0 / (lower_len + upper_len)\n",
    "    \n",
    "    s = p * gini(lower) + (1 - p) * gini(upper)\n",
    "    gain = current - s\n",
    "    \n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output: \n",
    "    def __init__(self,rows):\n",
    "        self.prediction = most_frequent(class_counts(rows))\n",
    "    \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    \n",
    "    def __init__(self,cutoff,attr,true,false): \n",
    "        self.true = true\n",
    "        self.false = false\n",
    "        self.attr = attr\n",
    "        self.cutoff = cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(dataset): \n",
    "    best_gain = -10\n",
    "    best_attr = 0 \n",
    "    best_cutoff = 0\n",
    "    \n",
    "    current = gini(dataset)\n",
    "    \n",
    "    features = dataset.columns[:-1]\n",
    "    \n",
    "    for attr in features:\n",
    "        cutoff = set(dataset[attr])\n",
    "        for cut in cutoff:\n",
    "            upper,lower = part(dataset,cut,attr)\n",
    "            if(len(upper)==0 or len(lower)==0): \n",
    "                continue\n",
    "           \n",
    "            gain = info_gain(upper,lower,current)\n",
    "            if(gain>best_gain): \n",
    "                best_gain = gain\n",
    "                best_attr = attr\n",
    "                best_cutoff = cut\n",
    "        \n",
    "    return best_gain, best_attr, best_cutoff\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part(dataset,cutoff,attr):\n",
    "    \n",
    "    upper = dataset[dataset[attr]>cutoff]\n",
    "    lower = dataset[dataset[attr]<=cutoff]\n",
    "    \n",
    "    return upper,lower\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(dataset,depth,greedy): \n",
    "    \n",
    "    best_gain, best_attr,best_cutoff = best_split(dataset)\n",
    "    if greedy:\n",
    "        if(best_gain<=0):\n",
    "            return Output(dataset)\n",
    "    else: \n",
    "        if(depth==0 or len(dataset)<5): \n",
    "            return Output(dataset)\n",
    "    \n",
    "    upper,lower = part(dataset,best_cutoff,best_attr)\n",
    "    \n",
    "    true_branch = build_tree(upper,depth-1,greedy)\n",
    "    false_branch = build_tree(lower,depth-1,greedy)\n",
    "    \n",
    "    return Decision_Node(best_cutoff,best_attr,true_branch,false_branch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check a given row for the condition.\n",
    "def check(row,node):\n",
    "    at = node.attr\n",
    "    \n",
    "    if(row[at]>node.cutoff):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A classification for iris datase\n",
    "def classify_iris(row,node):\n",
    "    if isinstance(node,Output): \n",
    "        return node.prediction\n",
    "    else: \n",
    "        if(check(row,node)):\n",
    "            return classify_iris(row,node.true)\n",
    "        else:\n",
    "            return classify_iris(row,node.false)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the data into train and test.\n",
    "def divide_data(dataset):\n",
    "    attr = dataset.columns\n",
    "    train = []\n",
    "    test = []\n",
    "    for index,row in dataset.iterrows():\n",
    "        if(index%3==0):\n",
    "            test.append(row)\n",
    "        else: \n",
    "            train.append(row)\n",
    "    return pd.DataFrame(train),pd.DataFrame(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on the test set\n",
    "def accuracy(test,tree):\n",
    "    accurate = 0\n",
    "    cnt = 0\n",
    "    listed = test.values.tolist()\n",
    "    for index,row in test.iterrows(): \n",
    "        cnt+=1\n",
    "        if(row.tolist()[-1]==classify_iris(row,tree)):\n",
    "            accurate+=1\n",
    "    return 1.0*accurate/cnt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_features(dataset,m):\n",
    "    features = dataset.columns[:-1].tolist()\n",
    "    chosen_names = sample(features,m)\n",
    "    chosen_names.append(dataset.columns[-1])\n",
    "\n",
    "    return dataset[chosen_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1(a) Extending the Decision tree to build random forests.\n",
    "def random_forest(dataset,m,n,depth): \n",
    "    tree_arr = []\n",
    "    for i in range(n):\n",
    "        tree_arr.append([])\n",
    "        trimmed = random_features(dataset,m)\n",
    "    \n",
    "        tree_ = build_tree(trimmed,depth,False)\n",
    "        tree_arr[i] = tree_\n",
    "    return tree_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_forests(tree_arr,test):\n",
    "    accuracy = 0\n",
    "    cnt = 0\n",
    "    for index,row in test.iterrows(): \n",
    "        output_array = []\n",
    "        cnt+=1\n",
    "        for node in tree_arr:\n",
    "            decision = classify_iris(row,node)\n",
    "            output_array.append(decision)\n",
    "        prediction = most_common(output_array)\n",
    "        if row.tolist()[-1] == prediction:\n",
    "            accuracy+=1\n",
    "    return 1.0*accuracy/cnt\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Random Forests  0.94\n",
      "Accuracy with single Tree 0.9\n"
     ]
    }
   ],
   "source": [
    "#Q1 (D)Accuracy on the IRIS dataset.\n",
    "dataset = pd.read_csv('iris.csv') \n",
    "train,test = divide_data(dataset)\n",
    "tree_arr = random_forest(train,2,20,2)\n",
    "\n",
    "acc1 = test_random_forests(tree_arr, test)\n",
    "tree_train = build_tree(train,3,True)\n",
    "acc2 = accuracy(test,tree_train)\n",
    "\n",
    "print(\"Accuracy using Random Forests \", acc1) \n",
    "print(\"Accuracy with single Tree\", acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_cross_valid(total_data):\n",
    "    estimator_list = [1,2,5,10,50,100]\n",
    "    max_acc = 0\n",
    "    opt_est = 0\n",
    "    for est in estimator_list:\n",
    "        \n",
    "        train_data = total_data[:120]\n",
    "        test_data = total_data[120:150]\n",
    "        \n",
    "        #Using 2 paramaters and depth of 2\n",
    "        \n",
    "        tree_arr = random_forest(train_data,2,est,2)\n",
    "        acc1 = test_random_forests(tree_arr,test_data)\n",
    "\n",
    "        train_data = total_data[30:150]\n",
    "        test_data = total_data[0:30]\n",
    "        \n",
    "        tree_arr = random_forest(train_data,2,est,2)\n",
    "        acc2 = test_random_forests(tree_arr,test_data)\n",
    "\n",
    "        test_data = total_data[30:60]\n",
    "        train_data = pd.concat([total_data[:30],total_data[60:150]])\n",
    "        \n",
    "        tree_arr = random_forest(train_data,2,est,2)\n",
    "        acc3 = test_random_forests(tree_arr,test_data)\n",
    "        \n",
    "        test_data = total_data[60:90]\n",
    "        train_data = pd.concat([total_data[:60],total_data[90:150]])\n",
    "        \n",
    "        tree_arr = random_forest(train_data,2,est,2)\n",
    "        acc4 = test_random_forests(tree_arr,test_data)\n",
    "\n",
    "        test_data = total_data[90:120]\n",
    "        train_data = pd.concat([total_data[:90],total_data[120:150]])\n",
    "        \n",
    "        tree_arr = random_forest(train_data,2,est,2)\n",
    "        acc5 = test_random_forests(tree_arr,test_data)\n",
    "        \n",
    "        avg_acc = (acc1+acc2+acc3+acc4+acc5)/5.\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(avg_acc>max_acc):\n",
    "            max_acc = avg_acc\n",
    "            opt_est = est\n",
    "        \n",
    "    \n",
    "    \n",
    "    return max_acc,opt_est \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1(e) Randomly doing sampling of the data\n",
    "\n",
    "dataset = dataset.sample(frac = 1)\n",
    "\n",
    "#Finding optimal accuracy and number of estimators.\n",
    "\n",
    "max_acc, opt_est = forest_cross_valid(dataset)\n",
    "print (\"the optimal estimator is\",opt_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
